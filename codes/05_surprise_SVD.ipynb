{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6092ae80-db1b-477a-83d5-637afdce1986",
   "metadata": {},
   "source": [
    "We will make use of scikit surprise package to build a collaborative-filtering recommender system based on explicit ratings. We will be using a matrix factorisation algorithm for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eef2848-b7f9-42e6-8f5e-d93f695a825a",
   "metadata": {},
   "source": [
    "## Contents:\n",
    "- [Installation-of-Packages](#Installation-of-Packages)\n",
    "- [Loading of Libraries](#Loading-of-Libraries) \n",
    "- [Loading of Datasets & Preprocessing](#Loading-of-Datasets-&-Preprocessing)\n",
    "- [Baseline Model - SVD Algorithm](#Baseline-Model---SVD-Algorithm)\n",
    "- [Model Tuning using GridSearch](#Model-Tuning-using-GridSearch)\n",
    "- [Using Best Params of GridSearch2](#Using-Best-Params-of-GridSearch2)\n",
    "  - [Generating rating predictions](#Generating-rating-predictions)\n",
    "  - [Additional metrics](#Additional-metrics)\n",
    "  - [Generating shuffled location recommendations](#Generating-shuffled-location-recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ace9734-65cd-4e73-b49c-39394a609c0e",
   "metadata": {},
   "source": [
    "## Installation of Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fec5c245-64e6-43ad-8998-c9e5823243be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-surprise\n",
      "  Downloading scikit-surprise-1.1.3.tar.gz (771 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m772.0/772.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: joblib>=1.0.0 in /Users/jo/mambaforge/envs/dsi-sg/lib/python3.8/site-packages (from scikit-surprise) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/jo/mambaforge/envs/dsi-sg/lib/python3.8/site-packages (from scikit-surprise) (1.22.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/jo/mambaforge/envs/dsi-sg/lib/python3.8/site-packages (from scikit-surprise) (1.7.3)\n",
      "Building wheels for collected packages: scikit-surprise\n",
      "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.3-cp38-cp38-macosx_10_9_x86_64.whl size=1131466 sha256=24f12c372c81fa0da05ce38d63effca63a5cf084af5a55da3311000f7c0ad144\n",
      "  Stored in directory: /Users/jo/Library/Caches/pip/wheels/e0/44/15/6d6010d88d0e8e3694643a009f445df00a74c79c938e2c0dd4\n",
      "Successfully built scikit-surprise\n",
      "Installing collected packages: scikit-surprise\n",
      "Successfully installed scikit-surprise-1.1.3\n"
     ]
    }
   ],
   "source": [
    "# !pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7799b4d-635e-473a-8875-8505134a430b",
   "metadata": {},
   "source": [
    "## Loading of Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f98102d-9d67-4065-abb0-6f06067f967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# imports form surprise\n",
    "from surprise import accuracy, Dataset, Reader, SVD\n",
    "from surprise.model_selection import cross_validate, GridSearchCV, KFold\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn import preprocessing # import label encoder\n",
    "\n",
    "import difflib # helpers for computing deltas\n",
    "import random\n",
    "\n",
    "import pickle # to save and load models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d555251a-7657-40a0-ae38-f5c2de84d0e5",
   "metadata": {},
   "source": [
    "## Loading of Datasets & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "9aa13b72-d0a3-4066-9505-2030c9efb590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(177607, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profile_id</th>\n",
       "      <th>location_id</th>\n",
       "      <th>cts</th>\n",
       "      <th>sentiment_pred</th>\n",
       "      <th>name</th>\n",
       "      <th>city</th>\n",
       "      <th>cd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.519805e+06</td>\n",
       "      <td>1178180.0</td>\n",
       "      <td>2016-06-09 22:13:32</td>\n",
       "      <td>3</td>\n",
       "      <td>la famiglia</td>\n",
       "      <td>London, United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.594847e+08</td>\n",
       "      <td>1178180.0</td>\n",
       "      <td>2019-05-30 23:17:22</td>\n",
       "      <td>3</td>\n",
       "      <td>la famiglia</td>\n",
       "      <td>London, United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.364797e+09</td>\n",
       "      <td>1178180.0</td>\n",
       "      <td>2019-05-26 15:27:27</td>\n",
       "      <td>3</td>\n",
       "      <td>la famiglia</td>\n",
       "      <td>London, United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.213894e+08</td>\n",
       "      <td>857670431.0</td>\n",
       "      <td>2019-05-30 21:41:15</td>\n",
       "      <td>2</td>\n",
       "      <td>green park</td>\n",
       "      <td>London, United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.243066e+08</td>\n",
       "      <td>857670431.0</td>\n",
       "      <td>2019-05-30 07:56:50</td>\n",
       "      <td>3</td>\n",
       "      <td>green park</td>\n",
       "      <td>London, United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     profile_id  location_id                  cts  sentiment_pred  \\\n",
       "0  4.519805e+06    1178180.0  2016-06-09 22:13:32               3   \n",
       "1  2.594847e+08    1178180.0  2019-05-30 23:17:22               3   \n",
       "2  6.364797e+09    1178180.0  2019-05-26 15:27:27               3   \n",
       "3  2.213894e+08  857670431.0  2019-05-30 21:41:15               2   \n",
       "4  6.243066e+08  857670431.0  2019-05-30 07:56:50               3   \n",
       "\n",
       "          name                    city  cd  \n",
       "0  la famiglia  London, United Kingdom  GB  \n",
       "1  la famiglia  London, United Kingdom  GB  \n",
       "2  la famiglia  London, United Kingdom  GB  \n",
       "3   green park  London, United Kingdom  GB  \n",
       "4   green park  London, United Kingdom  GB  "
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading of dataset\n",
    "recsys_df = pd.read_csv('./instagram-dataset/recsys_df_name.csv')\n",
    "print(recsys_df.shape)\n",
    "recsys_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "e0e9878d-45a3-4180-b72d-2179109867ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_encoder object knows how to understand word labels\n",
    "label_encoder = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "fefe8a3a-c7cc-4004-bc4f-9ff29caac029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels in column 'name'\n",
    "recsys_df['new_location_id']= label_encoder.fit_transform(recsys_df['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "3ce11965-c4a3-4139-810f-665f8b92f349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profile_id</th>\n",
       "      <th>location_id</th>\n",
       "      <th>cts</th>\n",
       "      <th>sentiment_pred</th>\n",
       "      <th>name</th>\n",
       "      <th>city</th>\n",
       "      <th>cd</th>\n",
       "      <th>new_location_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.519805e+06</td>\n",
       "      <td>1178180.0</td>\n",
       "      <td>2016-06-09 22:13:32</td>\n",
       "      <td>3</td>\n",
       "      <td>la famiglia</td>\n",
       "      <td>London, United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "      <td>3433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.594847e+08</td>\n",
       "      <td>1178180.0</td>\n",
       "      <td>2019-05-30 23:17:22</td>\n",
       "      <td>3</td>\n",
       "      <td>la famiglia</td>\n",
       "      <td>London, United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "      <td>3433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.364797e+09</td>\n",
       "      <td>1178180.0</td>\n",
       "      <td>2019-05-26 15:27:27</td>\n",
       "      <td>3</td>\n",
       "      <td>la famiglia</td>\n",
       "      <td>London, United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "      <td>3433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.213894e+08</td>\n",
       "      <td>857670431.0</td>\n",
       "      <td>2019-05-30 21:41:15</td>\n",
       "      <td>2</td>\n",
       "      <td>green park</td>\n",
       "      <td>London, United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "      <td>2646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.243066e+08</td>\n",
       "      <td>857670431.0</td>\n",
       "      <td>2019-05-30 07:56:50</td>\n",
       "      <td>3</td>\n",
       "      <td>green park</td>\n",
       "      <td>London, United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "      <td>2646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     profile_id  location_id                  cts  sentiment_pred  \\\n",
       "0  4.519805e+06    1178180.0  2016-06-09 22:13:32               3   \n",
       "1  2.594847e+08    1178180.0  2019-05-30 23:17:22               3   \n",
       "2  6.364797e+09    1178180.0  2019-05-26 15:27:27               3   \n",
       "3  2.213894e+08  857670431.0  2019-05-30 21:41:15               2   \n",
       "4  6.243066e+08  857670431.0  2019-05-30 07:56:50               3   \n",
       "\n",
       "          name                    city  cd  new_location_id  \n",
       "0  la famiglia  London, United Kingdom  GB             3433  \n",
       "1  la famiglia  London, United Kingdom  GB             3433  \n",
       "2  la famiglia  London, United Kingdom  GB             3433  \n",
       "3   green park  London, United Kingdom  GB             2646  \n",
       "4   green park  London, United Kingdom  GB             2646  "
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check new location labels\n",
    "recsys_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "5bf8fa3c-916d-444c-b9ef-340808deb6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and export\n",
    "recsys_df.to_csv('./instagram-dataset/recsys_df_update.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095a3605-92cb-47cd-ac17-ff4ae67e02b6",
   "metadata": {},
   "source": [
    "## Baseline Model - SVD Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ea547aa-2bbb-4b61-84d6-0623d7e9b83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate reader\n",
    "reader = Reader(rating_scale=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ac61bb2-7481-421a-adce-9060dd8fb61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate dataset \n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "data = Dataset.load_from_df(recsys_df[[\"profile_id\", \"new_location_id\", \"sentiment_pred\"]], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f298f50-8f48-4597-89d3-d5355d439667",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Evaluating RMSE, MSE, MAE of algorithm SVD on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "RMSE (testset)    0.6121  0.6111  0.6105  0.6112  0.0007  \n",
      "MSE (testset)     0.3747  0.3734  0.3727  0.3736  0.0008  \n",
      "MAE (testset)     0.5291  0.5284  0.5281  0.5286  0.0004  \n",
      "Fit time          1.36    1.42    1.41    1.39    0.03    \n",
      "Test time         0.64    0.62    0.48    0.58    0.07    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.61212084, 0.61105601, 0.6104864 ]),\n",
       " 'test_mse': array([0.37469193, 0.37338944, 0.37269364]),\n",
       " 'test_mae': array([0.52910472, 0.52843588, 0.52810968]),\n",
       " 'fit_time': (1.3552472591400146, 1.4156239032745361, 1.4137771129608154),\n",
       " 'test_time': (0.6435410976409912, 0.6164758205413818, 0.4824199676513672)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-validate an SVD model using three-fold cross-validation\n",
    "svd = SVD(verbose=True, n_epochs=10)\n",
    "cross_validate(svd, data, measures=['RMSE','MSE', 'MAE'], cv=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c481b728-1a88-41d2-b823-dfa8cc55f534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "RMSE: 0.5226\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.522637121227586"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding training metrics rmse\n",
    "trainset = data.build_full_trainset()\n",
    "svd.fit(trainset)\n",
    "\n",
    "testset = trainset.build_testset()\n",
    "predictions = svd.test(testset)\n",
    "accuracy.rmse(predictions, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b9989c4-8209-41f5-b9e2-edd5d1ee7fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "MSE: 0.2732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2731655672682671"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding training metrics mse\n",
    "trainset = data.build_full_trainset()\n",
    "svd.fit(trainset)\n",
    "\n",
    "testset = trainset.build_testset()\n",
    "predictions = svd.test(testset)\n",
    "accuracy.mse(predictions, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aef49bfb-2930-476f-b552-150a925ba38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "MAE:  0.4433\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.44333588025935755"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding training metrics mae\n",
    "trainset = data.build_full_trainset()\n",
    "svd.fit(trainset)\n",
    "\n",
    "testset = trainset.build_testset()\n",
    "predictions = svd.test(testset)\n",
    "accuracy.mae(predictions, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6442810f-2044-4645-9a52-50ffc29e32bb",
   "metadata": {},
   "source": [
    "- The performance of the baseline model is as follows:\n",
    "\n",
    "|Metric|train rmse|test rmse|train mse|test mse|train mae|test mae|\n",
    "|---|---|---|---|---|---|---|\n",
    "|Baseline|0.5226|0.6112|0.2732|0.3736|0.4433|0.5286|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb80746-8331-4181-b09d-f38052d4dbcc",
   "metadata": {},
   "source": [
    "- Comparing the train and test metrics, the train metrics are lower than the test metrics significantly so the model is overfitting.\n",
    "- We will attempt to GridSearch for the best parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f334033-f37e-46d5-8ea2-b826a4519898",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Tuning using GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffba486f-b952-4f98-8e0b-baa150d25212",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### GridSearch1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "63069766-2ea8-4426-8e0a-31211c913275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search over the following values of hyperparameters:\n",
    "# Number of factors: 60, 80\n",
    "# Number of epochs: 5, 10, 15, 20, 25\n",
    "# Learning rate for all parameters: 0.002, 0.003, 0.004\n",
    "# Regularization term for all parameters: 10 random values\n",
    "\n",
    "param_grid = {\"n_factors\": [60, 80],\n",
    "              \"n_epochs\": [5, 10, 15, 20, 25], \n",
    "              \"lr_all\": [0.002, 0.003, 0.004], \n",
    "              \"reg_all\": np.linspace(0.04, 2, 10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "06b0b690-7d0c-4f16-a966-34c34a66db6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV using cv=5\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['RMSE','MSE', 'MAE'], cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "86703c41-d0c9-4799-ae18-6e8ec6410474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52min 34s, sys: 29.9 s, total: 53min 4s\n",
      "Wall time: 54min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Fit GridSearch to training data\n",
    "gs.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "458595d0-fe67-4ffe-a007-254e72411f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test rmse: 0.6071656479964327\n",
      "Test best params: {'n_factors': 80, 'n_epochs': 25, 'lr_all': 0.004, 'reg_all': 0.4755555555555555}\n",
      "Test mse: 0.3686529094191794\n",
      "Test best params: {'n_factors': 80, 'n_epochs': 25, 'lr_all': 0.004, 'reg_all': 0.4755555555555555}\n",
      "Test mae: 0.5170955894700094\n",
      "Test best params: {'n_factors': 80, 'n_epochs': 25, 'lr_all': 0.004, 'reg_all': 0.04}\n"
     ]
    }
   ],
   "source": [
    "# Print metric score and combination of parameters that gave the best metric score\n",
    "for metric in ['rmse','mse', 'mae']:\n",
    "    print(f'Test {metric}: {gs.best_score[metric]}')\n",
    "    print(f'Test best params: {gs.best_params[metric]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "eff1eb7f-2ef7-406b-bbd3-65ebf62e9a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5202581078998157"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding training metrics rmse\n",
    "algo1 = gs.best_estimator['rmse']\n",
    "trainset = data.build_full_trainset()\n",
    "algo1.fit(trainset)\n",
    "\n",
    "testset = trainset.build_testset()\n",
    "predictions = algo1.test(testset)\n",
    "\n",
    "accuracy.rmse(predictions, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1f5a5492-54ee-4962-b8f5-a754c5271fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.2706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.27063659396251577"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding training metrics mse\n",
    "algo2 = gs.best_estimator['mse']\n",
    "trainset = data.build_full_trainset()\n",
    "algo2.fit(trainset)\n",
    "\n",
    "testset = trainset.build_testset()\n",
    "predictions = algo2.test(testset)\n",
    "\n",
    "accuracy.mse(predictions, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "10e46ec2-614b-45d3-9a28-397ae339c9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.4002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.40018532564143827"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding training metrics mae\n",
    "algo3 = gs.best_estimator['mae']\n",
    "trainset = data.build_full_trainset()\n",
    "algo3.fit(trainset)\n",
    "\n",
    "testset = trainset.build_testset()\n",
    "predictions = algo3.test(testset)\n",
    "\n",
    "accuracy.mae(predictions, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa01c9c-dda1-4112-b430-1d6674b59bff",
   "metadata": {},
   "source": [
    "- The results after GridSearch1 are as follows:\n",
    "\n",
    "|Metric|train rmse|test rmse|train mse|test mse|train mae|test mae|\n",
    "|---|---|---|---|---|---|---|\n",
    "|Baseline|0.5226|0.6112|0.2732|0.3736|0.4433|0.5286|\n",
    "|GridSearch1|0.5203|0.6072|0.2706|0.3687|0.4002|0.5170|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436d3372-4c56-4673-ab70-2f73519f2918",
   "metadata": {},
   "source": [
    "- The metrics across rmse, mse and mae have improved compared to the baseline model.\n",
    "- The model is less overfitting since most of the train and test metrics are closer with GridSearch1.\n",
    "- We will now attempt to reduce the learning rate and increase the regularization term to counter the overfitting problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7ca31f-4cf6-4b62-93bf-b277a4ce3ea5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### GridSearch2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "3e59adfb-1a52-49d2-a5e9-7b54341cd3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search over the following values of hyperparameters:\n",
    "# Number of epochs: 35, 40\n",
    "# Learning rate for all parameters: 0.002, 0.003\n",
    "# Regularization term for all parameters: 10 random values in np.linspace(0.2, 1, 10)\n",
    "\n",
    "param_grid2 = {\"n_epochs\": [35, 40], \n",
    "              \"lr_all\": [0.002, 0.003], \n",
    "              \"reg_all\": np.linspace(0.2, 1, 10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "9cfae3f4-e556-4c95-a4f5-be5363f76406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV using cv=5\n",
    "gs2 = GridSearchCV(SVD, param_grid2, measures=['rmse','mse', 'mae'], cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "fa79b5e3-206a-47b5-8bd5-602190919115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15min 54s, sys: 8.03 s, total: 16min 2s\n",
      "Wall time: 16min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Fit GridSearch to training data\n",
    "gs2.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "92e747de-a6c6-4957-af28-ed19e51b6024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test rmse: 0.6068985188787803\n",
      "Test best params: {'n_epochs': 40, 'lr_all': 0.003, 'reg_all': 0.5555555555555556}\n",
      "Test mse: 0.3683400036076808\n",
      "Test best params: {'n_epochs': 40, 'lr_all': 0.003, 'reg_all': 0.5555555555555556}\n",
      "Test mae: 0.5193380526382191\n",
      "Test best params: {'n_epochs': 40, 'lr_all': 0.003, 'reg_all': 0.2}\n"
     ]
    }
   ],
   "source": [
    "# Print metric score and combination of parameters that gave the best metric score\n",
    "for metric in ['rmse','mse', 'mae']:\n",
    "    print(f'Test {metric}: {gs2.best_score[metric]}')\n",
    "    print(f'Test best params: {gs2.best_params[metric]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "cd477e7a-0530-4976-8939-c2224c558e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5117\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.511692197835627"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding training metrics rmse\n",
    "algo1 = gs2.best_estimator['rmse']\n",
    "trainset = data.build_full_trainset()\n",
    "algo1.fit(trainset)\n",
    "\n",
    "testset = trainset.build_testset()\n",
    "predictions = algo1.test(testset)\n",
    "\n",
    "accuracy.rmse(predictions, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "bf59c40a-9371-4edb-ac40-9d3353607666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.2618\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2617794890754093"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding training metrics mse\n",
    "algo2 = gs2.best_estimator['mse']\n",
    "trainset = data.build_full_trainset()\n",
    "algo2.fit(trainset)\n",
    "\n",
    "testset = trainset.build_testset()\n",
    "predictions = algo2.test(testset)\n",
    "\n",
    "accuracy.mse(predictions, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "6fe74ac7-3bbb-4b49-870b-17c188e2089d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.4061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.40607407603765117"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding training metrics mae\n",
    "algo3 = gs2.best_estimator['mae']\n",
    "trainset = data.build_full_trainset()\n",
    "algo3.fit(trainset)\n",
    "\n",
    "testset = trainset.build_testset()\n",
    "predictions = algo3.test(testset)\n",
    "\n",
    "accuracy.mae(predictions, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d9ab3f-1381-447d-9e22-73ea4464c808",
   "metadata": {},
   "source": [
    "- The results after GridSearch2 is as follows:\n",
    "\n",
    "|Metric|train rmse|test rmse|train mse|test mse|train mae|test mae|\n",
    "|---|---|---|---|---|---|---|\n",
    "|Baseline|0.5226|0.6112|0.2732|0.3736|0.4433|0.5286|\n",
    "|GridSearch1|0.5203|0.6072|0.2706|0.3687|0.4002|0.5170|\n",
    "|GridSearch2|0.5117|0.6069|0.2618|0.3683|0.4061|0.5193|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe9a6e3-3c7a-4839-a3dd-7fd90bc6bdd8",
   "metadata": {},
   "source": [
    "- The metrics have improved after GridSearch2.\n",
    "- Although the model is still overfitting, the train and test metrics for the targetted mae are closer.\n",
    "- As such, we will employ the model from GridSearch2 with a train mae of 0.4061 and test mae of 0.5193.\n",
    "- The best params for mae are as follows:\n",
    "  - 'n_epochs': 40\n",
    "  - 'lr_all': 0.003\n",
    "  - 'reg_all': 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79776685-5b49-4d22-ae37-cb014993b5d6",
   "metadata": {},
   "source": [
    "## Using Best Params of GridSearch2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "137bf3b4-f79b-487f-a752-e1b62e9473f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7fb35730e4c0>"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the algorithm that yields the best mse\n",
    "algo = gs2.best_estimator[\"mae\"]\n",
    "algo.fit(data.build_full_trainset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "d42fdfd5-506c-48e2-baf6-09774ec14bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and export model\n",
    "pickle.dump(algo, open('./output/model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d038af56-c581-44e3-b341-7329e1b75131",
   "metadata": {},
   "source": [
    "#### Generating rating predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "02c03197-8332-431c-88d9-1084dfa45342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid=4519805, iid=2646, r_ui=None, est=2.4620357763065255, details={'was_impossible': False})"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict rating for profile_id=4519805 for new_location_id=2646\n",
    "algo.predict(uid=4519805, iid=2646)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbc362c-3e8e-4884-a83f-c9d8d68a442e",
   "metadata": {},
   "source": [
    "- Based on the prediction output, profile4519805 will give an estimated rating of 2.5/3 for location2646. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a92159f-d1f0-4220-9aa1-4b16ba101225",
   "metadata": {},
   "source": [
    "#### Additional metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d79493-a63c-46c9-b0d2-3116e6a7e765",
   "metadata": {},
   "source": [
    "To calculate precision@k and recall@k, we will set k=100 (top 100 recommendations) and threshold=2.5 (out of 3) for a positive rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "4a7296e4-a23f-443e-981a-b85b7e80868c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute precision@k and recall@k\n",
    "def precision_recall_at_k(predictions, k=100, threshold=2.5):\n",
    "    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(\n",
    "            ((true_r >= threshold) and (est >= threshold))\n",
    "            for (est, true_r) in user_ratings[:k]\n",
    "        )\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        # When n_rec_k is 0, Precision is undefined. We will set it to 1.\n",
    "\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        # When n_rel is 0, Recall is undefined. We will set it to 1.\n",
    "\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
    "\n",
    "    return precisions, recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "5a77da81-150c-447d-9627-06f53c3b72bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "fe7ec0d9-25ea-421f-9b38-adf2fada34df",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_list = []\n",
    "recall_list = []\n",
    "\n",
    "for trainset, testset in kf.split(data):\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=100, threshold=2.5)\n",
    "    \n",
    "    precision_list.append(sum(prec for prec in precisions.values()) / len(precisions))\n",
    "    recall_list.append(sum(rec for rec in recalls.values()) / len(recalls))\n",
    "\n",
    "# Precision and recall can then be averaged over all users\n",
    "precision_ave = sum(precision_list)/len(precision_list)\n",
    "recall_ave = sum(recall_list)/len(recall_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "b3a38fa4-086d-47dd-a7c7-01bade72813d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8031610013744401 0.7748232536921323\n"
     ]
    }
   ],
   "source": [
    "print(precision_ave, recall_ave)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b84eed4-9845-4133-8396-f593855baf2a",
   "metadata": {},
   "source": [
    "- Out of the top 100 recommendations and a threshold of 2.5 out of 3 for a positive rating, the model is able to predict with a precision@k value of 0.8031 and recall@k value of 0.7748 which are acceptable.\n",
    "- We will move on to generate recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59adb06d-a424-4313-9289-fedc0c4c0c50",
   "metadata": {},
   "source": [
    "#### Generating shuffled location recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "4eb8e10b-3430-43f8-a248-333e4c6316f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get location recommendations\n",
    "def get_location_id(name, metadata):\n",
    "    \n",
    "    \"\"\"\n",
    "    Gets the location ID for a location name based on the closest match in the metadata dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    existing_names = list(metadata['name'].values)\n",
    "    closest_names = difflib.get_close_matches(name, existing_names)\n",
    "    new_location_id = metadata[metadata['name'] == closest_names[0]]['new_location_id'].values[0]\n",
    "    return new_location_id\n",
    "\n",
    "def get_location_info(new_location_id, metadata):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns some basic information about a location given the location id and the metadata dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    location_info = metadata[metadata['new_location_id'] == new_location_id][['name', \n",
    "                                                    'city', 'cd']]\n",
    "    return location_info.to_dict(orient='records')\n",
    "\n",
    "def predict_rating(profile_id, name, model, metadata):\n",
    "    \n",
    "    \"\"\"\n",
    "    Predicts the review (on a scale of 1-3) that a user would assign to a specific location \n",
    "    \"\"\"\n",
    "    \n",
    "    pickled_model = pickle.load(open('./output/model.pkl', 'rb'))\n",
    "    new_location_id = get_location_id(name, metadata)\n",
    "    rating_prediction = pickled_model.predict(uid=profile_id, iid=new_location_id)\n",
    "    return rating_prediction.est\n",
    "\n",
    "def generate_recommendation(profile_id, model, metadata, thresh=2.5):\n",
    "    \n",
    "    \"\"\"\n",
    "    Generates a location recommendation for a user based on a rating threshold. Only\n",
    "    books with a predicted rating at or above the threshold will be recommended\n",
    "    \"\"\"\n",
    "    \n",
    "    if profile_id in metadata['profile_id'].values:\n",
    "        names = list(metadata['name'].values)\n",
    "        random.shuffle(names)\n",
    "        for name in names:\n",
    "            rating = predict_rating(profile_id, name, model, metadata)\n",
    "            if rating >= thresh:\n",
    "                new_location_id = get_location_id(name, metadata)\n",
    "                return get_location_info(new_location_id, metadata)[0]\n",
    "    else:\n",
    "        # counter cold start problem by recommending top 20 rated locations\n",
    "        print(f\"Looks like you're not a member yet. Why not join now for better recommendation?\")\n",
    "        names = recsys_df.groupby(['name']).count().sort_values(by='profile_id', ascending=False).head(20).index.values\n",
    "        random.shuffle(names)\n",
    "        for name in names:\n",
    "            new_location_id = get_location_id(name, metadata)\n",
    "            return (get_location_info(new_location_id, metadata)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "d7231c08-ebdb-4354-9e09-929e00f36b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'garden room at the lanesborough, london',\n",
       " 'city': 'London, United Kingdom',\n",
       " 'cd': 'GB'}"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate location recommendation for profile4519805 who is in dataset\n",
    "generate_recommendation(4519805, algo, recsys_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "37050a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looks like you're not a member yet. Why not join now for better recommendation?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'chinatown', 'city': 'London, United Kingdom', 'cd': 'GB'}"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate location recommendation for profile1 who is not in dataset\n",
    "generate_recommendation(1, algo, recsys_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6449f9-604f-4263-aa20-f329ef23e0bb",
   "metadata": {},
   "source": [
    "- We will proceed to fitting another matrix factorisation model available on scikit surprise, NMF, and compare the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeeffcd6-5665-42d9-8a0f-b11c054f84bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
